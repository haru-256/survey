# Learning Diverse Rankings with Multi-Armed Bandits

- Auther
  - Filip Radlinski
  - Robert Kleinberg
  - Thorsten Joachims
- Source
  - ICML 2008

# Why Selected this Paper?

現在（2021-03-21）、ファセットのリランキングをbanditを用いて取り組んでいる。このタスクはランク学習に属するもので、以下の手法が考えられる。

- biasをモデル化したランク学習
- biasをモデル化せず、オンラインによる逐次最適化によるランク学習

通常のWebサイトはbiasが様々であり、モデル化するのが難しい。そこでbanditを用いたオンライン学習を選択した。これまで2回banditでファセットランキングをしたが、売上のリフト（CTRの上昇）は見られなかった。そこで今一度基本に戻り、どういった手法があるのかを調査することにした。これはbanditによるランク学習を定式化した初めての論文であるため、この論文を選択した。

# どんなもの？



# 先行研究と比べてどこがすごい？

以下の3つの点で異なる新しいランク学習の問題定式化を提案した。

1. 学習データ。以前の手法は手作業でラベル付けられたデータの関係性を用いた学習する。しかし、この手法ではWebサイト等での使用データを用いて学習する。使用データは量も多くコストも少ない。
2. 使用データからのオンライン学習方法。
3. ドキュメント間の関係性を考慮し、多様性のあるランキングを提示。クエリはユーザーの応じてコトンラウ意味を持つことがしばしばなので、多様性のあるランキングは好まれる

# 関連研究・比較研究は？



# 技術や手法のキモはどこ？
# どうやって有効だと検証した？
# 議論はある？
# 次に読むべき論文は？

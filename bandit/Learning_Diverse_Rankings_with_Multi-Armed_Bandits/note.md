# Learning Diverse Rankings with Multi-Armed Bandits

- Auther
  - Filip Radlinski
  - Robert Kleinberg
  - Thorsten Joachims
- Source
  - ICML 2008

# Why Selected this Paper?

現在（2021-03-21）、ファセットのリランキングをbanditを用いて取り組んでいる。このタスクはランク学習に属するもので、以下の手法が考えられる。

- biasをモデル化したランク学習
- biasをモデル化せず、オンラインによる逐次最適化によるランク学習

MonotaROではbiasが様々であり、モデル化するのが難しい。そこでbanditを用いたオンライン学習を選択した。これまで2回banditでファセットランキングをしたが、売上のリフト（CTRの上昇）は見られなかった。そこで今一度基本に戻り、どういった手法があるのかを調査することにした。これはbanditによるランク学習を定式化した初めての論文であるため、この論文を選択した。

# どんなもの？

以下の貢献をした。

- 以下の3つの点で異なる新しいランク学習の問題定式化を提案した。
   1. 使用されるデータ
   2. 

# 先行研究と比べてどこがすごい？
# 技術や手法のキモはどこ？
# どうやって有効だと検証した？
# 議論はある？
# 次に読むべき論文は？
